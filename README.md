# Portfolio Code Repository

## Overview
This repository contains the source code used in my portfolio projects.  
For detailed explanations, please visit:<br><br>
ğŸ”— https://giyonglee.com


## Projects

### Uplift Modeling
X-Learner-based Uplift Modeling for Advertising Incremental Effect Estimation

#### Project info
- Directory: `/uplift`  
- Portfolio: [ê´‘ê³  ì¦ë¶„ íš¨ê³¼ ì¶”ì •ì„ ìœ„í•œ X-learner ê¸°ë°˜ì˜ ì—…ë¦¬í”„íŠ¸ ëª¨ë¸ êµ¬í˜„ ë° ì‹¤í—˜](https://giyonglee.com/posts/5)
- Dataset: [Criteo Uplift Prediction Dataset](https://ailab.criteo.com/criteo-uplift-prediction-dataset/)

#### Workflow
1. `data.py` â€“ data preprocessing
2. `train.py` â€“ XGBoost model training
3. `evaluate.py` â€“ model evaluation
4. `uplift.py` â€“ X-Learner uplift estimation
5. `report.py` â€“ uplift performance evaluation

### Multi-Touch Attribution
Comparison of Attention-based GRU and Transformer Models for Multi-Touch Attribution

#### Project info
- Directory: `/attribution`  
- Portfolio: [Attention ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•œ GRU ë° Transformer ê¸°ë°˜ ë©€í‹° í„°ì¹˜ ì–´íŠ¸ë¦¬ë·°ì…˜ ëª¨ë¸ ë¹„êµ ì—°êµ¬](https://giyonglee.com/posts/4) 
- Dataset: [Criteo Attribution Modeling for Bidding Dataset](https://ailab.criteo.com/criteo-attribution-modeling-bidding-dataset/)  
  
#### Workflow
1. `data.py` â€“ data preprocessing  
2. `optimize.py` â€“ hyperparameter optimization (GRU / Transformer)  
3. `train.py` â€“ final model training with optimized parameters  
4. `attribution.py` â€“ conversion prediction  
5. `evaluate.py` â€“ prediction performance evaluation  
6. `report.py` â€“ attention-based attribution analysis  


## Experiments

### Tracking validation
- Simulation scripts for validating GA4/GTM event collection
- Checks page views, scroll, click, engagement time, traffic parameter
- Directory: `/traffic_simulation`
- workflow:
  1. `utils.py` - common utilities for request handling and event configuration
  2. `steps.py` - defines simulated user interaction steps
  3. `simulate.py` - executes traffic simulation and triggers events

### A/B Test Statistical Analysis
- Exploratory comparison of statistical inference approaches for A/B testing.
- Comparison of Neymanâ€“Pearson and Bayesian sequential approaches for A/B test result interpretation.
- Neymanâ€“Pearson 
  - Directory: `/ab_neyman` 
  - Dataset: simulated dataset (`dataset/fake_ab_test_2000.csv`)
- Bayesian sequential 
  - Directory: `/ab_beysian`
  - Dataset: [ASOS Digital Experiments Dataset](https://osf.io/64jsb/overview)

